{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de1c84a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 2/2 [00:00<00:00, 9565.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VARIANTE 1 — Sem τ, final_marking = {p_c:1} ===\n",
      "\n",
      "--- RESUMO ---\n",
      "trace | trace_is_fit | trace_fitness | missing_tokens | remaining_tokens | consumed_tokens | produced_tokens\n",
      "------+--------------+---------------+----------------+------------------+-----------------+----------------\n",
      "    1 | True         | 1             | 0              | 0                | 4               | 4              \n",
      "    2 | False        | 0.666667      | 1              | 1                | 3               | 3              \n",
      "\n",
      "--- DETALHADO ---\n",
      "\n",
      "Trace 1\n",
      "            trace_is_fit: True\n",
      "           trace_fitness: 1\n",
      "          missing_tokens: 0\n",
      "        remaining_tokens: 0\n",
      "         consumed_tokens: 4\n",
      "         produced_tokens: 4\n",
      "         reached_marking: p_c\n",
      "  enabled_transitions_in_marking: \n",
      "   activated_transitions: (A, 'A'), (B, 'B'), (C, 'C')\n",
      "  transitions_with_problems: \n",
      "\n",
      "Trace 2\n",
      "            trace_is_fit: False\n",
      "           trace_fitness: 0.666667\n",
      "          missing_tokens: 1\n",
      "        remaining_tokens: 1\n",
      "         consumed_tokens: 3\n",
      "         produced_tokens: 3\n",
      "         reached_marking: p_a, p_c\n",
      "  enabled_transitions_in_marking: (B, 'B')\n",
      "   activated_transitions: (A, 'A'), (C, 'C')\n",
      "  transitions_with_problems: (C, 'C')\n",
      "\n",
      "--- TABELA (Markdown) ---\n",
      "| trace | trace_is_fit | trace_fitness | missing | remaining | consumed | produced |\n",
      "|---:|:---:|---:|---:|---:|---:|---:|\n",
      "| 1 | True | 1 | 0 | 0 | 4 | 4 |\n",
      "| 2 | False | 0.666667 | 1 | 1 | 3 | 3 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 2/2 [00:00<00:00, 8516.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VARIANTE 2 — Com τ explícita, final_marking = {p_end:1} ===\n",
      "\n",
      "--- RESUMO ---\n",
      "trace | trace_is_fit | trace_fitness | missing_tokens | remaining_tokens | consumed_tokens | produced_tokens\n",
      "------+--------------+---------------+----------------+------------------+-----------------+----------------\n",
      "    1 | True         | 1             | 0              | 0                | 5               | 5              \n",
      "    2 | False        | 0.75          | 1              | 1                | 4               | 4              \n",
      "\n",
      "--- DETALHADO ---\n",
      "\n",
      "Trace 1\n",
      "            trace_is_fit: True\n",
      "           trace_fitness: 1\n",
      "          missing_tokens: 0\n",
      "        remaining_tokens: 0\n",
      "         consumed_tokens: 5\n",
      "         produced_tokens: 5\n",
      "         reached_marking: p_end\n",
      "  enabled_transitions_in_marking: \n",
      "   activated_transitions: (A, 'A'), (B, 'B'), (C, 'C'), (tau_end, None)\n",
      "  transitions_with_problems: \n",
      "\n",
      "Trace 2\n",
      "            trace_is_fit: False\n",
      "           trace_fitness: 0.75\n",
      "          missing_tokens: 1\n",
      "        remaining_tokens: 1\n",
      "         consumed_tokens: 4\n",
      "         produced_tokens: 4\n",
      "         reached_marking: p_a, p_end\n",
      "  enabled_transitions_in_marking: (B, 'B')\n",
      "   activated_transitions: (A, 'A'), (C, 'C'), (tau_end, None)\n",
      "  transitions_with_problems: (C, 'C')\n",
      "\n",
      "--- TABELA (Markdown) ---\n",
      "| trace | trace_is_fit | trace_fitness | missing | remaining | consumed | produced |\n",
      "|---:|:---:|---:|---:|---:|---:|---:|\n",
      "| 1 | True | 1 | 0 | 0 | 5 | 5 |\n",
      "| 2 | False | 0.75 | 1 | 1 | 4 | 4 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Script integrado: construção de log/modelo, execução do Token-Based Replay (TBR)\n",
    "e impressão de resultados de forma formatada (resumo, detalhado e Markdown).\n",
    "\"\"\"\n",
    "\n",
    "from typing import Any, Dict, Iterable, List, Tuple\n",
    "\n",
    "from pm4py.objects.log.obj import EventLog, Trace, Event\n",
    "from pm4py.objects.petri_net.obj import PetriNet, Marking\n",
    "from pm4py.objects.petri_net.utils import petri_utils\n",
    "from pm4py.algo.conformance.tokenreplay import algorithm as token_based_replay\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1) UTILITÁRIOS DE FORMATAÇÃO\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def _fmt_scalar(x: Any) -> str:\n",
    "    if x is None:\n",
    "        return \"—\"\n",
    "    if isinstance(x, float):\n",
    "        return f\"{x:.6g}\"\n",
    "    return str(x)\n",
    "\n",
    "\n",
    "def _fmt_iter(xs: Iterable[Any]) -> str:\n",
    "    try:\n",
    "        return \", \".join(_fmt_scalar(x) for x in xs)\n",
    "    except TypeError:\n",
    "        return _fmt_scalar(xs)\n",
    "\n",
    "\n",
    "def _take(d: Dict[str, Any], keys: List[str]) -> Dict[str, Any]:\n",
    "    return {k: d.get(k) for k in keys}\n",
    "\n",
    "\n",
    "def pretty_print_tbr(replay_result: List[Dict[str, Any]], title: str = \"\") -> None:\n",
    "    \"\"\"Imprime resumo tabular e bloco detalhado por traço.\"\"\"\n",
    "    if title:\n",
    "        print(f\"\\n=== {title} ===\")\n",
    "    if not replay_result:\n",
    "        print(\"Resultado vazio.\")\n",
    "        return\n",
    "\n",
    "    # Resumo por traço\n",
    "    header = [\n",
    "        \"trace\",\n",
    "        \"trace_is_fit\",\n",
    "        \"trace_fitness\",\n",
    "        \"missing_tokens\",\n",
    "        \"remaining_tokens\",\n",
    "        \"consumed_tokens\",\n",
    "        \"produced_tokens\",\n",
    "    ]\n",
    "    widths = [max(len(h), 5) for h in header]\n",
    "    fmt_row = \" | \".join(f\"{{:{w}}}\" for w in widths)\n",
    "    sep = \"-+-\".join(\"-\" * w for w in widths)\n",
    "\n",
    "    print(\"\\n--- RESUMO ---\")\n",
    "    print(fmt_row.format(*header))\n",
    "    print(sep)\n",
    "\n",
    "    for i, r in enumerate(replay_result, start=1):\n",
    "        row = [\n",
    "            i,\n",
    "            _fmt_scalar(r.get(\"trace_is_fit\")),\n",
    "            _fmt_scalar(r.get(\"trace_fitness\")),\n",
    "            _fmt_scalar(r.get(\"missing_tokens\")),\n",
    "            _fmt_scalar(r.get(\"remaining_tokens\")),\n",
    "            _fmt_scalar(r.get(\"consumed_tokens\")),\n",
    "            _fmt_scalar(r.get(\"produced_tokens\")),\n",
    "        ]\n",
    "        print(fmt_row.format(*row))\n",
    "\n",
    "    # Detalhado\n",
    "    print(\"\\n--- DETALHADO ---\")\n",
    "    for i, r in enumerate(replay_result, start=1):\n",
    "        print(f\"\\nTrace {i}\")\n",
    "        main_keys = [\n",
    "            \"trace_is_fit\",\n",
    "            \"trace_fitness\",\n",
    "            \"missing_tokens\",\n",
    "            \"remaining_tokens\",\n",
    "            \"consumed_tokens\",\n",
    "            \"produced_tokens\",\n",
    "        ]\n",
    "        for k, v in _take(r, main_keys).items():\n",
    "            print(f\"  {k:>22}: {_fmt_scalar(v)}\")\n",
    "\n",
    "        for k in [\"reached_marking\", \"enabled_transitions_in_marking\"]:\n",
    "            if k in r:\n",
    "                print(f\"  {k:>22}: {_fmt_iter(r[k])}\")\n",
    "\n",
    "        for k in [\"activated_transitions\", \"transitions_with_problems\"]:\n",
    "            if k in r:\n",
    "                print(f\"  {k:>22}: {_fmt_iter(r[k])}\")\n",
    "\n",
    "\n",
    "def tbr_to_markdown_table(replay_result: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"Gera tabela Markdown com as métricas principais por traço.\"\"\"\n",
    "    lines = [\n",
    "        \"| trace | trace_is_fit | trace_fitness | missing | remaining | consumed | produced |\",\n",
    "        \"|---:|:---:|---:|---:|---:|---:|---:|\",\n",
    "    ]\n",
    "    for i, r in enumerate(replay_result, start=1):\n",
    "        row = [\n",
    "            str(i),\n",
    "            _fmt_scalar(r.get(\"trace_is_fit\")),\n",
    "            _fmt_scalar(r.get(\"trace_fitness\")),\n",
    "            _fmt_scalar(r.get(\"missing_tokens\")),\n",
    "            _fmt_scalar(r.get(\"remaining_tokens\")),\n",
    "            _fmt_scalar(r.get(\"consumed_tokens\")),\n",
    "            _fmt_scalar(r.get(\"produced_tokens\")),\n",
    "        ]\n",
    "        lines.append(\"| \" + \" | \".join(row) + \" |\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def save_markdown_table(replay_result: List[Dict[str, Any]], path: str) -> None:\n",
    "    md = tbr_to_markdown_table(replay_result)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(md)\n",
    "    print(f\"Tabela Markdown salva em: {path}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2) CONSTRUÇÃO DO LOG SINTÉTICO\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def build_tiny_log() -> EventLog:\n",
    "    \"\"\"\n",
    "    Constrói um log com 2 trilhas:\n",
    "      - Trace1: A -> B -> C (conforme ao modelo linear)\n",
    "      - Trace2: A -> C      (desvio: pula B)\n",
    "    \"\"\"\n",
    "    log = EventLog()\n",
    "\n",
    "    trace1 = Trace()\n",
    "    trace1.append(Event({\"concept:name\": \"A\"}))\n",
    "    trace1.append(Event({\"concept:name\": \"B\"}))\n",
    "    trace1.append(Event({\"concept:name\": \"C\"}))\n",
    "    log.append(trace1)\n",
    "\n",
    "    trace2 = Trace()\n",
    "    trace2.append(Event({\"concept:name\": \"A\"}))\n",
    "    trace2.append(Event({\"concept:name\": \"C\"}))\n",
    "    log.append(trace2)\n",
    "\n",
    "    return log\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3) CONSTRUÇÃO DO MODELO (REDE DE PETRI)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def build_linear_abc(\n",
    "    use_tau_and_pend: bool = False,\n",
    ") -> Tuple[PetriNet, Marking, Marking]:\n",
    "    \"\"\"\n",
    "    Constrói a rede linear:\n",
    "        p_start -> A -> p_a -> B -> p_b -> C -> p_c [-> tau_end -> p_end (opcional)]\n",
    "    Se 'use_tau_and_pend' = False:\n",
    "        final_marking = {p_c: 1}  (traço A-B-C é perfeitamente conforme)\n",
    "    Se 'use_tau_and_pend' = True:\n",
    "        adiciona tau_end e p_end, e exige final_marking = {p_end: 1}\n",
    "        (o TBR pode ou não disparar τ para fechar; resultado depende da variante)\n",
    "    \"\"\"\n",
    "    net = PetriNet(\"Exemplo\")\n",
    "\n",
    "    # Lugares\n",
    "    p_start = PetriNet.Place(\"p_start\")\n",
    "    p_a = PetriNet.Place(\"p_a\")\n",
    "    p_b = PetriNet.Place(\"p_b\")\n",
    "    p_c = PetriNet.Place(\"p_c\")\n",
    "    net.places.update({p_start, p_a, p_b, p_c})\n",
    "\n",
    "    # Transições observáveis\n",
    "    t_a = PetriNet.Transition(\"A\", \"A\")\n",
    "    t_b = PetriNet.Transition(\"B\", \"B\")\n",
    "    t_c = PetriNet.Transition(\"C\", \"C\")\n",
    "    net.transitions.update({t_a, t_b, t_c})\n",
    "\n",
    "    # Conectividade principal\n",
    "    petri_utils.add_arc_from_to(p_start, t_a, net)\n",
    "    petri_utils.add_arc_from_to(t_a, p_a, net)\n",
    "    petri_utils.add_arc_from_to(p_a, t_b, net)\n",
    "    petri_utils.add_arc_from_to(t_b, p_b, net)\n",
    "    petri_utils.add_arc_from_to(p_b, t_c, net)\n",
    "    petri_utils.add_arc_from_to(t_c, p_c, net)\n",
    "\n",
    "    # Marcação inicial\n",
    "    im = Marking({p_start: 1})\n",
    "\n",
    "    if not use_tau_and_pend:\n",
    "        # Sem τ: exige terminar em p_c\n",
    "        fm = Marking({p_c: 1})\n",
    "        return net, im, fm\n",
    "\n",
    "    # Com τ e p_end explícitos\n",
    "    t_end = PetriNet.Transition(\"tau_end\", None)\n",
    "    net.transitions.add(t_end)\n",
    "    p_end = PetriNet.Place(\"p_end\")\n",
    "    net.places.add(p_end)\n",
    "    petri_utils.add_arc_from_to(p_c, t_end, net)\n",
    "    petri_utils.add_arc_from_to(t_end, p_end, net)\n",
    "\n",
    "    fm = Marking({p_end: 1})\n",
    "    return net, im, fm\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4) EXECUÇÃO DO TBR E IMPRESSÃO\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def run_and_report(\n",
    "    log: EventLog, net: PetriNet, im: Marking, fm: Marking, title: str\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Executa TBR, imprime resultados formatados e retorna o replay_result.\"\"\"\n",
    "    replay_result = token_based_replay.apply(log, net, im, fm)\n",
    "    pretty_print_tbr(replay_result, title=title)\n",
    "    print(\"\\n--- TABELA (Markdown) ---\")\n",
    "    print(tbr_to_markdown_table(replay_result))\n",
    "    return replay_result\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5) MAIN\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    log = build_tiny_log()\n",
    "\n",
    "    # Variante 1: sem τ; final em p_c (traço A-B-C deve ter fitness = 1)\n",
    "    net1, im1, fm1 = build_linear_abc(use_tau_and_pend=False)\n",
    "    run_and_report(\n",
    "        log, net1, im1, fm1, title=\"VARIANTE 1 — Sem τ, final_marking = {p_c:1}\"\n",
    "    )\n",
    "\n",
    "    # Variante 2: com τ e p_end; final em p_end (resultado depende se a τ é disparada no fechamento)\n",
    "    net2, im2, fm2 = build_linear_abc(use_tau_and_pend=True)\n",
    "    run_and_report(\n",
    "        log,\n",
    "        net2,\n",
    "        im2,\n",
    "        fm2,\n",
    "        title=\"VARIANTE 2 — Com τ explícita, final_marking = {p_end:1}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec440f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import annotations\n",
    "from typing import Dict, Iterable, List, Tuple, Union, Mapping, Sequence\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "from pm4py.objects.log.obj import EventLog, Trace, Event\n",
    "from pm4py.objects.log.exporter.xes import exporter as xes_exporter\n",
    "\n",
    "ActivitySeq = Union[str, Sequence[str]]\n",
    "FreqTable = Union[\n",
    "    Mapping[Tuple[str, ...], int],  # {('a','c','d'): 10, ...}\n",
    "    Iterable[Tuple[int, ActivitySeq]],  # [(10, \"a,c,d\"), (5, ('a','b')),...]\n",
    "]\n",
    "\n",
    "\n",
    "def _parse_trace(trace: ActivitySeq) -> Tuple[str, ...]:\n",
    "    \"\"\"Aceita 'a,c,d' | '(a, c, d, e, h)' | ['a','c','d'] e devolve ('a','c','d').\"\"\"\n",
    "    if isinstance(trace, (list, tuple)):\n",
    "        return tuple(str(x).strip() for x in trace)\n",
    "    s = str(trace).strip()\n",
    "    # remove parênteses e espaços, separa por vírgula\n",
    "    if s.startswith(\"(\") and s.endswith(\")\"):\n",
    "        s = s[1:-1]\n",
    "    parts = [p.strip() for p in s.split(\",\") if p.strip()]\n",
    "    return tuple(parts)\n",
    "\n",
    "\n",
    "def _normalize_freq_table(table: FreqTable) -> List[Tuple[Tuple[str, ...], int]]:\n",
    "    \"\"\"Converte qualquer formato aceito para lista padronizada [(('a','b'), 3), ...].\"\"\"\n",
    "    if isinstance(table, Mapping):\n",
    "        return [(tuple(k), int(v)) for k, v in table.items()]\n",
    "    out: List[Tuple[Tuple[str, ...], int]] = []\n",
    "    for freq, tr in table:\n",
    "        out.append((_parse_trace(tr), int(freq)))\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_xes_from_frequencies(\n",
    "    freq_table: FreqTable,\n",
    "    out_path: str,\n",
    "    *,\n",
    "    # como a tabela original: a,b,c,d,e,f,g,h\n",
    "    activity_labels: Mapping[str, str] | None = None,\n",
    "    # geração opcional de timestamps sintéticos\n",
    "    add_timestamps: bool = True,\n",
    "    base_time: datetime | None = None,\n",
    "    delta_between_cases: timedelta = timedelta(minutes=3),\n",
    "    delta_between_events: timedelta = timedelta(seconds=15),\n",
    "    # políticas de nomes de cases\n",
    "    case_prefix: str = \"σ\",\n",
    "    keep_activity_letters_in_concept_name: bool = True,\n",
    ") -> EventLog:\n",
    "    \"\"\"\n",
    "    Gera um XES a partir de uma tabela de frequências de traços.\n",
    "    - freq_table: mapeamento ou lista com (freq, trace)\n",
    "    - out_path: caminho do arquivo .xes a ser salvo\n",
    "    - activity_labels: mapeia 'a'->'register request', etc. (opcional)\n",
    "    - add_timestamps: se True, cria timestamps sintéticos e ciclo de vida 'complete'\n",
    "    - keep_activity_letters_in_concept_name: se True, 'concept:name' do evento = letra (ex.: 'a').\n",
    "      O rótulo semântico, se fornecido, vai em 'activity:label'.\n",
    "    Retorna o EventLog criado.\n",
    "    \"\"\"\n",
    "    rows = _normalize_freq_table(freq_table)\n",
    "    log = EventLog()\n",
    "\n",
    "    # base temporal\n",
    "    if add_timestamps:\n",
    "        if base_time is None:\n",
    "            base_time = datetime.now(timezone.utc).replace(microsecond=0)\n",
    "        current_case_start = base_time\n",
    "    else:\n",
    "        current_case_start = None  # type: ignore\n",
    "\n",
    "    case_counter = 0\n",
    "    for trace_idx, (activities, freq) in enumerate(rows, start=1):\n",
    "        for rep in range(freq):\n",
    "            case_counter += 1\n",
    "            tr = Trace()\n",
    "            # id do case no nível de traço (XES: concept:name no trace)\n",
    "            tr.attributes[\"concept:name\"] = f\"{case_prefix}{case_counter}\"\n",
    "\n",
    "            # gerar eventos\n",
    "            if add_timestamps:\n",
    "                t0 = current_case_start\n",
    "            for pos, act in enumerate(activities):\n",
    "                # concept:name do evento = letra por padrão (importante para alinhamento)\n",
    "                ev_name = (\n",
    "                    act\n",
    "                    if keep_activity_letters_in_concept_name\n",
    "                    else activity_labels.get(act, act) if activity_labels else act\n",
    "                )\n",
    "                e = Event({\"concept:name\": ev_name})\n",
    "\n",
    "                # rótulo semântico adicional (opcional)\n",
    "                if activity_labels:\n",
    "                    e[\"activity:label\"] = activity_labels.get(act, act)\n",
    "\n",
    "                if add_timestamps:\n",
    "                    e[\"time:timestamp\"] = t0 + pos * delta_between_events  # type: ignore\n",
    "                    e[\"lifecycle:transition\"] = \"complete\"\n",
    "\n",
    "                tr.append(e)\n",
    "\n",
    "            log.append(tr)\n",
    "\n",
    "            if add_timestamps:\n",
    "                current_case_start += (\n",
    "                    delta_between_cases  # próxima instância começa depois\n",
    "                )\n",
    "\n",
    "    # exporta\n",
    "    xes_exporter.apply(log, out_path)\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead5672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedroeckel/phd/projects/petro/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "exporting log, completed traces :: 100%|██████████| 967/967 [00:00<00:00, 22175.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XES salvo em: Lfull.xes  - casos: 967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ACT_LABELS = {\n",
    "    \"a\": \"register request\",\n",
    "    \"b\": \"examine thoroughly\",\n",
    "    \"c\": \"examine casually\",\n",
    "    \"d\": \"check ticket\",\n",
    "    \"e\": \"decide\",\n",
    "    \"f\": \"reinitiate request\",\n",
    "    \"g\": \"pay compensation\",\n",
    "    \"h\": \"reject request\",\n",
    "}\n",
    "\n",
    "freqs = [\n",
    "    (455, \"(a, c, d, e, h)\"),\n",
    "    (191, \"a, b, d, e, g\"),\n",
    "    (177, \"a, d, e, g\"),\n",
    "    (144, \"a, b, d, e, h\"),\n",
    "    # ... complete com as restantes linhas se desejar\n",
    "]\n",
    "\n",
    "log = build_xes_from_frequencies(\n",
    "    freqs,\n",
    "    out_path=\"Lfull.xes\",\n",
    "    activity_labels=ACT_LABELS,  # opcional (só para legenda)\n",
    "    add_timestamps=True,  # gera tempos sintéticos\n",
    "    keep_activity_letters_in_concept_name=True,  # mantém 'a','b',... em concept:name\n",
    ")\n",
    "print(f\"XES salvo em: Lfull.xes  - casos: {len(log)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
